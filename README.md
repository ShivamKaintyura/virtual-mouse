Custom Gesture-Controlled Virtual Mouse
This project is a gesture-based virtual mouse system that allows users to interact with their computer using hand movements captured via webcam. The novelty of this project lies in its customizable gesture controlâ€”users can assign specific actions (like left-click, right-click, scroll, drag) to hand gestures of their choice.

ğŸ§  Features
ğŸ–ï¸ Real-time hand tracking using webcam
ğŸ–±ï¸ Control mouse movement with hand position
ğŸ‘† Customizable gestures for different mouse actions
ğŸ› ï¸ Smooth user experience with minimal latency
ğŸ”’ No external hardware requiredâ€”just a webcam
ğŸ“Œ Technologies Used
Programming Language: Python
Libraries:
OpenCV â€“ for image processing
Mediapipe â€“ for accurate hand detection and tracking
PyAutoGUI â€“ for controlling mouse actions
Tkinter (optional) â€“ for the gesture-action mapping interface
âš™ï¸ How It Works
The webcam captures hand gestures in real-time.
MediaPipe detects and tracks key points of the hand.
Based on gesture patterns (like number of fingers up), the system identifies the intended action.
Users can customize which gesture triggers which action using a simple interface.
PyAutoGUI executes the corresponding mouse command on screen.
